#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BBC ä¸­æ–‡æ–°èçˆ¬èŸ² - Python ç‰ˆæœ¬
çˆ¬å– BBC ä¸­æ–‡ç¶² RSS æ–°èè³‡æ–™
"""

import json
import time
import random
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional
from pathlib import Path
import sys

import requests
from bs4 import BeautifulSoup
from fake_useragent import UserAgent

def get_random_user_agent() -> str:
    """ç²å–éš¨æ©Ÿ User-Agent"""
    try:
        ua = UserAgent()
        return ua.random
    except Exception:
        return "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"

def random_delay(min_seconds: float = 1.0, max_seconds: float = 3.0) -> None:
    """éš¨æ©Ÿå»¶é²"""
    delay = random.uniform(min_seconds, max_seconds)
    print(f"â³ éš¨æ©Ÿå»¶é² {delay:.2f} ç§’...")
    time.sleep(delay)

def parse_rss_feed(xml_content: str) -> List[Dict[str, Any]]:
    """è§£æ RSS XML å…§å®¹"""
    articles = []
    
    try:
        soup = BeautifulSoup(xml_content, 'xml')
        
        # ç²å–é »é“è³‡è¨Š
        channel = soup.find('channel')
        if not channel:
            print("âŒ æœªæ‰¾åˆ° RSS channel")
            return []
        
        # è§£ææ‰€æœ‰æ–‡ç« é …ç›®
        items = channel.find_all('item')
        print(f"ğŸ“Š æ‰¾åˆ° {len(items)} ç¯‡æ–‡ç« ")
        
        for item in items:
            try:
                title_elem = item.find('title')
                link_elem = item.find('link')
                description_elem = item.find('description')
                pub_date_elem = item.find('pubDate')
                guid_elem = item.find('guid')
                
                # æå–ç¸®åœ– URL (å¯èƒ½åœ¨ description çš„ HTML ä¸­)
                thumbnail_url = None
                if description_elem and description_elem.get_text():
                    desc_soup = BeautifulSoup(description_elem.get_text(), 'html.parser')
                    img_tag = desc_soup.find('img')
                    if img_tag and img_tag.get('src'):
                        thumbnail_url = img_tag.get('src')
                
                article = {
                    "title": title_elem.get_text().strip() if title_elem else "",
                    "link": link_elem.get_text().strip() if link_elem else "",
                    "description": description_elem.get_text().strip() if description_elem else "",
                    "pubDate": pub_date_elem.get_text().strip() if pub_date_elem else "",
                    "guid": guid_elem.get_text().strip() if guid_elem else "",
                    "thumbnail": thumbnail_url
                }
                
                # åªæ·»åŠ æœ‰æ¨™é¡Œå’Œé€£çµçš„æ–‡ç« 
                if article["title"] and article["link"]:
                    articles.append(article)
                    
            except Exception as e:
                print(f"âš ï¸ è§£ææ–‡ç« æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        print(f"âœ… æˆåŠŸè§£æ {len(articles)} ç¯‡æ–‡ç« ")
        return articles
        
    except Exception as e:
        print(f"âŒ è§£æ RSS XML æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def scrape_bbc_rss() -> Optional[List[Dict[str, Any]]]:
    """çˆ¬å– BBC ä¸­æ–‡ç¶² RSS æ–°è"""
    rss_url = "https://feeds.bbci.co.uk/zhongwen/trad/rss.xml"
    
    headers = {
        'User-Agent': get_random_user_agent(),
        'Accept': 'application/rss+xml, application/xml, text/xml',
        'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    try:
        print("ğŸš€ é–‹å§‹çˆ¬å– BBC ä¸­æ–‡ç¶² RSS...")
        random_delay(1, 2)
        
        response = requests.get(rss_url, headers=headers, timeout=30)
        response.raise_for_status()
        response.encoding = 'utf-8'
        
        print("âœ… æˆåŠŸç²å– RSS å…§å®¹")
        
        # è§£æ RSS
        articles = parse_rss_feed(response.text)
        
        if articles:
            print(f"ğŸ“° æˆåŠŸçˆ¬å– {len(articles)} ç¯‡ BBC ä¸­æ–‡æ–°è")
            return articles
        else:
            print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•æ–°èæ–‡ç« ")
            return None
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ HTTP è«‹æ±‚éŒ¯èª¤: {e}")
        return None
    except Exception as e:
        print(f"âŒ çˆ¬å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def save_bbc_data(articles: List[Dict[str, Any]]) -> None:
    """å„²å­˜ BBC æ–°èè³‡æ–™"""
    # ç¢ºä¿ data ç›®éŒ„å­˜åœ¨
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    # å»ºç«‹è¼¸å‡ºè³‡æ–™çµæ§‹
    output_data = {
        "updated": datetime.now(timezone.utc).isoformat(),
        "source": "BBC Chinese RSS",
        "title": "BBC Chinese",
        "description": "BBC Chinese - BBC News , ä¸­æ–‡ - ä¸»é ",
        "link": "https://www.bbc.com/zhongwen/trad",
        "total_articles": len(articles),
        "articles": articles
    }
    
    # å„²å­˜ç‚º JSON
    output_path = data_dir / "bbc-trends.json"
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è³‡æ–™å·²å„²å­˜è‡³: {output_path}")
    except Exception as e:
        print(f"âŒ å„²å­˜è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def main() -> None:
    """ä¸»å‡½æ•¸"""
    print("ğŸ“° BBC ä¸­æ–‡æ–°èçˆ¬èŸ² - Python ç‰ˆæœ¬")
    print("==================================================")
    
    try:
        # çˆ¬å– BBC RSS æ–°è
        articles = scrape_bbc_rss()
        
        if articles:
            # å„²å­˜è³‡æ–™
            save_bbc_data(articles)
            
            # é¡¯ç¤ºçµæœæ‘˜è¦
            print("âœ… æ“·å–å®Œæˆ:")
            for i, article in enumerate(articles[:3], 1):
                print(f"  {i}. {article['title'][:60]}...")
            print(f"ğŸ“Š ç¸½å…±æ‰¾åˆ° {len(articles)} ç¯‡æ–°è")
        else:
            print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•æ–°èè³‡æ–™")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
