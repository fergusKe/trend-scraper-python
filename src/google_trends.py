#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google ç†±æœçˆ¬èŸ² - Python ç‰ˆæœ¬
çˆ¬å–å°ç£ Google ç†±æœæ¦œè³‡æ–™
"""

import json
import time
import random
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
from fake_useragent import UserAgent


def setup_driver() -> webdriver.Chrome:
    """è¨­å®š Chrome WebDriver"""
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-setuid-sandbox')
    
    # ä½¿ç”¨éš¨æ©Ÿ User-Agent
    ua = UserAgent()
    user_agent = ua.random
    options.add_argument(f'--user-agent={user_agent}')
    
    # è‡ªå‹•ä¸‹è¼‰ä¸¦å®‰è£æœ€æ–°çš„ ChromeDriver
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    
    return driver


def random_delay(min_seconds: float = 3, max_seconds: float = 13) -> None:
    """éš¨æ©Ÿå»¶é²"""
    delay = random.uniform(min_seconds, max_seconds)
    print(f"â³ éš¨æ©Ÿå»¶é² {delay:.2f} ç§’...")
    time.sleep(delay)


def scrape_google_trends() -> List[Dict[str, str]]:
    """çˆ¬å– Google ç†±æœè³‡æ–™"""
    driver = setup_driver()
    trends = []
    
    try:
        print("ğŸš€ é–‹å§‹çˆ¬å– Google ç†±æœ...")
        
        # éš¨æ©Ÿå»¶é²é¿å…è¢«åµæ¸¬
        random_delay(3, 13)
        
        # å‰å¾€ Google è¶¨å‹¢é é¢
        driver.get('https://trends.google.com.tw/trending?geo=TW&hours=4')
        
        # é é¢è¼‰å…¥å¾Œå†æ¬¡å»¶é²
        random_delay(3, 8)
        
        # ç­‰å¾…è¡¨æ ¼è¼‰å…¥
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "td"))
            )
            print("âœ… é é¢è¼‰å…¥å®Œæˆ")
        except TimeoutException:
            print("âš ï¸ ç­‰å¾…å…ƒç´ è¼‰å…¥è¶…æ™‚")
        
        # æ‰¾åˆ°æ‰€æœ‰è¡¨æ ¼è¡Œ
        rows = driver.find_elements(By.CSS_SELECTOR, "tbody tr")
        print(f"ğŸ“Š æ‰¾åˆ° {len(rows)} å€‹è¡¨æ ¼è¡Œ")
        
        # éæ¿¾å‡ºæœ‰æ•ˆçš„è³‡æ–™è¡Œï¼ˆåŒ…å«è¶…é3å€‹cellçš„è¡Œï¼‰
        data_rows = [row for row in rows if len(row.find_elements(By.TAG_NAME, "td")) > 3]
        print(f"ğŸ“Š æœ‰æ•ˆè³‡æ–™è¡Œ: {len(data_rows)} å€‹")
        
        for row in data_rows:
            try:
                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) <= 3:
                    continue
                
                trend_cell = cells[1]
                count_cell = cells[2]
                time_cell = cells[3]
                
                # æå–è¶¨å‹¢é—œéµå­—
                trend_text = ""
                trend_divs = trend_cell.find_elements(By.TAG_NAME, "div")
                for div in trend_divs:
                    text = div.text.strip()
                    if (text and 
                        "æ¬¡æœå°‹" not in text and 
                        "æ´»èº" not in text and 
                        "æŒçºŒæ™‚é–“" not in text and 
                        "Â·" not in text):
                        trend_text = text
                        break
                
                # æå–æœå°‹é‡
                count_text = count_cell.text.strip()
                search_volume = ""
                count_matches = re.findall(r'(\d+[\d,]*\+)', count_text)
                for match in count_matches:
                    if re.match(r'^\d+[\d,]*\+$', match):
                        search_volume = match
                        break
                
                # æå–é–‹å§‹æ™‚é–“
                time_text = time_cell.text.strip()
                time_match = re.search(r'(\d+\s*[å°æ™‚åˆ†é˜]+å‰)', time_text)
                started_time = time_match.group(1) if time_match else ""
                
                # å¦‚æœæ‰€æœ‰è³‡æ–™éƒ½é½Šå…¨ï¼ŒåŠ å…¥åˆ°çµæœä¸­
                if trend_text and search_volume and started_time:
                    trends.append({
                        "googleTrend": trend_text,
                        "searchVolume": search_volume,
                        "started": started_time
                    })
                    
            except Exception as e:
                print(f"âš ï¸ è§£æè¡Œæ™‚å‡ºéŒ¯: {e}")
                continue
        
    except Exception as e:
        print(f"âŒ çˆ¬å–éç¨‹ä¸­å‡ºéŒ¯: {e}")
    
    finally:
        driver.quit()
    
    return trends

def save_trends_data(trends: List[Dict[str, str]]) -> Path:
    """å„²å­˜è¶¨å‹¢è³‡æ–™åˆ° JSON æª”æ¡ˆ"""
    data = {
        "updated": datetime.now().isoformat() + "Z",
        "trends": trends
    }
    
    # ç¢ºä¿ data è³‡æ–™å¤¾å­˜åœ¨
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    # å¯«å…¥ JSON æª”æ¡ˆ
    output_file = data_dir / "google-trends.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ è³‡æ–™å·²å„²å­˜è‡³: {output_file}")
    return output_file


def main() -> None:
    """ä¸»å‡½æ•¸"""
    print("ğŸ” Google ç†±æœçˆ¬èŸ² - Python ç‰ˆæœ¬")
    print("=" * 50)
    
    # çˆ¬å–è³‡æ–™
    trends = scrape_google_trends()
    
    if trends:
        # å„²å­˜è³‡æ–™
        save_trends_data(trends)
        
        # é¡¯ç¤ºçµæœæ‘˜è¦
        print("âœ… æ“·å–å®Œæˆ:", trends[:5])
        print(f"ğŸ“Š ç¸½å…±æ‰¾åˆ° {len(trends)} å€‹è¶¨å‹¢")
    else:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•è¶¨å‹¢è³‡æ–™")

if __name__ == "__main__":
    main()
