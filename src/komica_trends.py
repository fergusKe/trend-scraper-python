#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Komica(Kå³¶) ç†±é–€æ–‡ç« çˆ¬èŸ² - Python ç‰ˆæœ¬
çˆ¬å– Kå³¶ ä»Šæ—¥ç†±é–€æ–‡ç«  Top 50
"""

import json
import time
import random
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
from fake_useragent import UserAgent

def setup_driver():
    """è¨­å®š Chrome WebDriver"""
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-setuid-sandbox')
    
    # ä½¿ç”¨éš¨æ©Ÿ User-Agent
    ua = UserAgent()
    user_agent = ua.random
    options.add_argument(f'--user-agent={user_agent}')
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    
    return driver

def parse_komica_line(line: str, link: str = None) -> Optional[Dict]:
    """è§£æ Komica æ–‡ç« è¡Œè³‡æ–™"""
    try:
        # ç§»é™¤è¡Œå°¾çš„"åœ¨æ–°åˆ†é é–‹å•Ÿ"æ–‡å­—
        line = line.replace('åœ¨æ–°åˆ†é é–‹å•Ÿ', '').strip()
        
        # åˆ†å‰²è³‡æ–™ - æ ¼å¼: å›è¦†æ•¸|ID|æ—¥æœŸ|æ™‚é–“|æ¨™é¡Œ|æè¿°
        parts = line.split('|')
        
        if len(parts) >= 6:
            reply_count_str = parts[0].strip()
            thread_id = parts[1].strip()
            date = parts[2].strip()
            time = parts[3].strip()
            title = parts[4].strip()
            description = parts[5].strip()
            
            # è½‰æ›å›è¦†æ•¸ç‚ºæ•´æ•¸
            try:
                reply_count = int(reply_count_str)
            except ValueError:
                reply_count = 0
            
            # ä½¿ç”¨æä¾›çš„é€£çµï¼Œæˆ–å»ºæ§‹é è¨­é€£çµ
            if link:
                final_link = link
            else:
                final_link = f"https://gita.komica1.org/00b/pixmicat.php?res={thread_id}"
            
            return {
                "replyCount": reply_count,
                "date": date,
                "time": time,
                "title": title,
                "description": description,
                "link": final_link,
                "rawText": line  # ä¿ç•™åŸå§‹æ–‡å­—ä»¥å‚™æŸ¥çœ‹
            }
            
    except Exception as e:
        print(f"âš ï¸ è§£æè¡Œè³‡æ–™æ™‚å‡ºéŒ¯: {e}")
        print(f"å•é¡Œè¡Œ: {line}")
    
    return None

def scrape_komica_trends():
    """çˆ¬å– Komica ç†±é–€æ–‡ç« """
    driver = setup_driver()
    trends = []
    
    try:
        print("ğŸš€ é–‹å§‹çˆ¬å– Komica ç†±é–€æ–‡ç« ...")
        
        # å‰å¾€ Komica é é¢
        driver.get('https://gita.komica1.org/00b/catlist.php')
        
        print("â³ è¼‰å…¥ç¶²é ...")
        
        # ç­‰å¾… pre æ¨™ç±¤è¼‰å…¥
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "pre"))
            )
            print("âœ… æ‰¾åˆ° pre æ¨™ç±¤")
        except TimeoutException:
            print("âš ï¸ ç­‰å¾… pre å…ƒç´ è¼‰å…¥è¶…æ™‚")
        
        # æ‰¾åˆ°æ‰€æœ‰ pre æ¨™ç±¤
        pre_elements = driver.find_elements(By.TAG_NAME, "pre")
        print(f"æ‰¾åˆ° pre æ¨™ç±¤æ•¸é‡: {len(pre_elements)}")
        
        # æ‰¾åˆ°åŒ…å«ä»Šæ—¥ç†±é–€çš„ pre æ¨™ç±¤
        today_threads_pre = None
        for i, pre in enumerate(pre_elements):
            pre_text = pre.text
            if "Top 50 Threads [Today]" in pre_text:
                today_threads_pre = pre
                print(f"âœ… åœ¨ç¬¬ {i+1} å€‹ pre æ¨™ç±¤ä¸­æ‰¾åˆ°ä»Šæ—¥ç†±é–€è¨è«–ä¸²")
                break
        
        if not today_threads_pre:
            print("âŒ æœªæ‰¾åˆ°åŒ…å«ä»Šæ—¥ç†±é–€è¨è«–ä¸²çš„ pre æ¨™ç±¤")
            # åˆ—å‡ºæ‰€æœ‰ pre æ¨™ç±¤çš„å…§å®¹ä¾›é™¤éŒ¯
            for i, pre in enumerate(pre_elements):
                content = pre.text[:100]  # åªé¡¯ç¤ºå‰100å€‹å­—å…ƒ
                print(f"Pre {i+1}: {content}...")
            return []
        
        # è§£æå…§å®¹
        print("ğŸ” é–‹å§‹è§£æä»Šæ—¥ç†±é–€è¨è«–ä¸²å…§å®¹...")
        
        # ç²å– HTML å…§å®¹è€Œä¸æ˜¯ç´”æ–‡å­—
        content = today_threads_pre.get_attribute('innerHTML')
        
        # æŒ‰è¡Œåˆ†å‰²
        lines = content.split('\n')
        
        # æ‰¾åˆ°åŒ…å«é€£çµçš„è¡Œ
        for line in lines:
            line = line.strip()
            
            # è·³éç©ºè¡Œ
            if not line:
                continue
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«é€£çµ
            if 'href=' in line and 'res=' in line:
                # æå–é€£çµ
                import re
                link_match = re.search(r'href="([^"]+)"', line)
                if link_match:
                    link = link_match.group(1)
                    
                    # ç§»é™¤ HTML æ¨™ç±¤ï¼Œä¿ç•™ç´”æ–‡å­—
                    raw_text = re.sub(r'<[^>]*>', '', line)
                    
                    # ç§»é™¤æ¨™é¡Œéƒ¨åˆ†
                    if 'Top 50 Threads [Today]' in raw_text:
                        raw_text = raw_text.replace('Top 50 Threads [Today]', '').strip()
                    
                    # ç¢ºä¿é‚„æœ‰å…§å®¹
                    if raw_text and '|' in raw_text:
                        trend_data = parse_komica_line(raw_text, link)
                        if trend_data:
                            trends.append(trend_data)
                            print(f"âœ… ç¬¬ {len(trends)} ç¯‡: {trend_data['title'][:40]}...")
        
        print(f"ğŸ“Š ç¸½å…±æ‰¾åˆ° {len(trends)} ç¯‡ç†±é–€æ–‡ç« ")
        
    except Exception as e:
        print(f"âŒ çˆ¬å–éç¨‹ä¸­å‡ºéŒ¯: {e}")
    
    finally:
        driver.quit()
    
    return trends

def save_komica_data(trends):
    """å„²å­˜ Komica è³‡æ–™åˆ° JSON æª”æ¡ˆ"""
    data = {
        "updated": datetime.now().isoformat() + "Z",
        "trends": trends
    }
    
    # ç¢ºä¿ data è³‡æ–™å¤¾å­˜åœ¨
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    # å¯«å…¥ JSON æª”æ¡ˆ
    output_file = data_dir / "komica-trends.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ è³‡æ–™å·²å„²å­˜è‡³: {output_file}")
    return output_file

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ Komica(Kå³¶) ç†±é–€æ–‡ç« çˆ¬èŸ² - Python ç‰ˆæœ¬")
    print("=" * 50)
    
    # çˆ¬å–è³‡æ–™
    trends = scrape_komica_trends()
    
    if trends:
        # å„²å­˜è³‡æ–™
        save_komica_data(trends)
        
        # é¡¯ç¤ºçµæœæ‘˜è¦
        print("âœ… çˆ¬å–å®Œæˆ!")
        print(f"ğŸ“Š ç¸½å…±æ‰¾åˆ° {len(trends)} ç¯‡ç†±é–€æ–‡ç« ")
        
        # é¡¯ç¤ºå‰å¹¾ç¯‡æ–‡ç« æ¨™é¡Œ
        for i, trend in enumerate(trends[:5], 1):
            print(f"{i}. [{trend.get('replyCount', 0)} å›è¦†] {trend.get('title', 'N/A')[:50]}...")
    else:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç†±é–€æ–‡ç« ")

if __name__ == "__main__":
    main()
